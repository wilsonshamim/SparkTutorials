create 2 txt files test1.txt and text2.txt files with some content.


import pyspark
from pyspark.sql import SQLContext
sc = pyspark.SparkContext(appName="app2")
inpfile=sc.textFile('test1.txt')
test=sc.textFile('test2.txt')


print(inpfile.collect())
print(inpfile.count())
print(inpfile.first())
print(inpfile.take(3))
print(inpfile.takeSample(False,3,4))
x = inpfile.map(lambda line : line.split(","))
print(x.take(5))
print(inpfile.union(test).collect())


-----------
collect() = this method will display the entire content.
count() = this method will display the count of the lines
first() = this will display the first line of the file
take(3) = this will display the first 3 lines.
inpfile.map(lambda line : line.split(",")) = this will split the comma seperated lines and display 
union() = this will merget the content of botht the files.


